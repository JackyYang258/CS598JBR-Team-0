/home/kaiyan3/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/kaiyan3/anaconda3/envs/598 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/kaiyan3/.mujoco/mujoco200/bin::/usr/lib/nvidia:/home/kaiyan3/.mujoco/mujoco210/bin:/home/kaiyan3/.mujoco/mujoco200/bin:/usr/lib/nvidia:/home/kaiyan3/.mujoco/mujoco210/bin:/home/kaiyan3/.mujoco/mujoco200/bin did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/home/kaiyan3/.vscode-server/extensions/ms-python.debugpy-2025.10.0-linux-x64/.noConfigDebugAdapterEndpoints/endpoint-b1a035162d7027c3.txt')}
  warn(msg)
Working with deepseek-ai/deepseek-coder-6.7b-instruct prompt type True...

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda128.so
False
CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...
CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 128
CUDA SETUP: Required library version not found: libbitsandbytes_cuda128.so. Maybe you need to compile it from source?
CUDA SETUP: Defaulting to libbitsandbytes_cpu.so...

================================================ERROR=====================================
CUDA SETUP: CUDA detection failed! Possible reasons:
1. CUDA driver not installed
2. CUDA not installed
3. You have multiple conflicting CUDA libraries
4. Required library not pre-compiled for this bitsandbytes release!
CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.
CUDA SETUP: The CUDA version for the compile might depend on your conda install. Inspect CUDA version via `conda list | grep cuda`.
================================================================================

CUDA SETUP: Something unexpected happened. Please compile from source:
git clone git@github.com:TimDettmers/bitsandbytes.git
cd bitsandbytes
CUDA_VERSION=128
python setup.py install
CUDA SETUP: Setup Failed!
Traceback (most recent call last):
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/transformers/utils/import_utils.py", line 1099, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 32, in <module>
    from ...modeling_utils import PreTrainedModel
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/transformers/modeling_utils.py", line 86, in <module>
    from accelerate import dispatch_model, infer_auto_device_map, init_empty_weights
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/accelerate/__init__.py", line 3, in <module>
    from .accelerator import Accelerator
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/accelerate/accelerator.py", line 35, in <module>
    from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/accelerate/checkpointing.py", line 24, in <module>
    from .utils import (
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/accelerate/utils/__init__.py", line 131, in <module>
    from .bnb import has_4bit_bnb_layers, load_and_quantize_model
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/accelerate/utils/bnb.py", line 42, in <module>
    import bitsandbytes as bnb
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/bitsandbytes/__init__.py", line 6, in <module>
    from . import cuda_setup, utils, research
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/bitsandbytes/research/__init__.py", line 1, in <module>
    from . import nn
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/bitsandbytes/research/nn/__init__.py", line 1, in <module>
    from .modules import LinearFP8Mixed, LinearFP8Global
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/bitsandbytes/research/nn/modules.py", line 8, in <module>
    from bitsandbytes.optim import GlobalOptimManager
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/bitsandbytes/optim/__init__.py", line 6, in <module>
    from bitsandbytes.cextension import COMPILED_WITH_CUDA
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/bitsandbytes/cextension.py", line 20, in <module>
    raise RuntimeError('''
RuntimeError: 
        CUDA Setup failed despite GPU being available. Please run the following command to get more information:

        python -m bitsandbytes

        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "task_1.py", line 148, in <module>
    results = prompt_model(dataset, model, vanilla)
  File "task_1.py", line 29, in prompt_model
    model = AutoModelForCausalLM.from_pretrained(
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 492, in from_pretrained
    model_class = _get_model_class(config, cls._model_mapping)
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 376, in _get_model_class
    supported_models = model_mapping[type(config)]
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 666, in __getitem__
    return self._load_attr_from_module(model_type, model_name)
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 680, in _load_attr_from_module
    return getattribute_from_module(self._modules[module_name], attr)
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 625, in getattribute_from_module
    if hasattr(module, attr):
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/transformers/utils/import_utils.py", line 1089, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/kaiyan3/anaconda3/envs/598/lib/python3.8/site-packages/transformers/utils/import_utils.py", line 1101, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):

        CUDA Setup failed despite GPU being available. Please run the following command to get more information:

        python -m bitsandbytes

        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues
